#!/bin/bash
set -euo pipefail

# Source the upstream entrypoint to get docker_init_database_dir and other functions
source /usr/local/bin/docker-entrypoint.sh

# Mount Point
BASE_DIR="/var/lib/postgresql"

get_bin_path() {
  local version=$1
  echo "/usr/lib/postgresql/$version/bin"
}

log() {
  echo "[ix-postgres-main]      - [$(date +'%Y-%m-%d %H:%M:%S')] - $1" >&2
}

up_log() {
  echo "[ix-postgres-upgrade]   - [$(date +'%Y-%m-%d %H:%M:%S')] - $1" >&2
}

dm_log() {
  echo "[ix-postgres-directory] - [$(date +'%Y-%m-%d %H:%M:%S')] - $1" >&2
}

empty_line() {
  echo ""; echo ""
}

get_data_size() {
  local path=$1
  du -sh "$path" 2>/dev/null | cut -f1
}

# TODO: Remove once postgres 17 is removed from Apps
resolve_timezone() {
  local tz="$1"
  local tz_path="/usr/share/zoneinfo/${tz}"

  if [ ! -e "$tz_path" ]; then
    log "ERROR: Timezone ${tz} not found"
    return 1
  fi

  # If it's a symlink (legacy), resolve it to canonical
  if [ -L "$tz_path" ]; then
    local target
    target=$(readlink -f "$tz_path")
    echo "${target#/usr/share/zoneinfo/}"
  else
    # Already canonical
    echo "$tz"
  fi
}

# TODO: Remove once postgres 17 is removed from Apps
migrate_timezone_parameter() {
  local pgconf="$1"
  local param_name="$2"

  # Extract current value from postgresql.conf
  local current_tz
  current_tz=$(grep -E "^${param_name}\s*=" "$pgconf" | sed -E "s|^${param_name}\s*=\s*'([^']+)'.*|\1|")

  if [ -z "$current_tz" ]; then
    log "No [${param_name}] found in config"
    return 0
  fi

  local canonical_tz
  canonical_tz=$(resolve_timezone "$current_tz")

  if [ "$current_tz" != "$canonical_tz" ]; then
    log "Migrating parameter [${param_name}] from [${current_tz}] -> [${canonical_tz}]"
    sed -i "s|^${param_name}\s*=\s*'${current_tz}'.*|${param_name} = '${canonical_tz}'|g" "$pgconf"
  else
    log "Parameter [${param_name}] is already canonical - [${current_tz}]"
  fi
}

# TODO: Remove once postgres 17 is removed from Apps
migrate_timezones() {
  local data_dir="$1"
  local pgconf="$data_dir/postgresql.conf"

  if [ ! -f "$pgconf" ]; then
    log "No postgresql.conf found at $pgconf, skipping timezone migration"
    return 0
  fi

  log "Starting timezone migration for $data_dir"
  for param in timezone log_timezone; do
    if ! migrate_timezone_parameter "$pgconf" "$param"; then
      log "WARNING: Timezone migration failed for parameter [$param]"
      return 1
    fi
  done
  log "Timezone migration complete"
}

run_post_upgrade_tasks() {
  local data_dir="$1"
  local sql_files="$2"

  up_log "Starting temporary PostgreSQL server to run post-upgrade tasks..."

  export PGPASSWORD="${PGPASSWORD:-$POSTGRES_PASSWORD}"
  export PGDATA="$data_dir"

  # Start temporary server
  docker_temp_server_start postgres

  # Refresh collations in all databases (including template1, but not template0)
  up_log "Refreshing collations in all databases..."
  psql --username "$POSTGRES_USER" --dbname postgres --tuples-only --no-align --command "SELECT datname FROM pg_database WHERE datallowconn;" | while read -r dbname; do
    if [ -n "$dbname" ]; then
      up_log "Refreshing collations in database [$dbname]"
      if psql --username "$POSTGRES_USER" --dbname "$dbname" --command "ALTER DATABASE \"$dbname\" REFRESH COLLATION VERSION;"; then
        up_log "Successfully refreshed collations in [$dbname]"
      else
        up_log "WARNING: Failed to refresh collations in [$dbname]"
      fi
    fi
  done

  # Run each SQL file if any were generated
  if [ -n "$sql_files" ]; then
    up_log "Found post-upgrade SQL scripts generated by pg_upgrade:"
    echo "$sql_files" | while read -r sql_file; do
      up_log "  - $sql_file"
    done

    echo "$sql_files" | while read -r sql_file; do
      if [ -f "$sql_file" ]; then
        up_log "Executing $sql_file..."
        if psql --username "$POSTGRES_USER" --dbname postgres --file "$sql_file"; then
          up_log "Successfully executed $sql_file"
          # Delete the script after successful execution
          rm -f "$sql_file"
          up_log "Deleted $sql_file after successful execution"
        else
          up_log "WARNING: Failed to execute $sql_file (keeping file for manual review)"
        fi
      fi
    done
  else
    up_log "No post-upgrade SQL scripts generated by pg_upgrade"
  fi

  # Stop temporary server
  docker_temp_server_stop
  unset PGPASSWORD

  up_log "Post-upgrade tasks completed"
  return 0
}

check_same_filesystem() {
  local old_location="$1"
  local new_location="$2"

  if [ "$(stat -c '%d' "$old_location")" != "$(stat -c '%d' "$new_location")" ]; then
    log "ERROR: Old location [$old_location] and new location [$new_location] are on different filesystems."
    return 1
  fi
  return 0
}

check_writable() {
  local path=$1
  if [ ! -w "$path" ]; then
    log "ERROR: Not writable path [$path]"
    return 1
  fi

  return 0
}

check_dir_owner_match() {
  local base_dir_owner
  local container_user
  base_dir_owner=$(stat -c '%u' "$1")
  container_user=$(id -u)
  if [ "$base_dir_owner" != "$container_user" ]; then
    log "ERROR: Base directory owner [$base_dir_owner] does not match container user [$container_user]"
    return 1
  fi
  return 0
}

# TODO: Remove once postgres 17 is removed from Apps
# Check if data exists in old structure and needs migration
detect_old_data_location() {
  if [ -f "$BASE_DIR/PG_VERSION" ]; then
    echo "$BASE_DIR"
    return 0
  fi
  return 1
}

# TODO: Remove once postgres 17 is removed from Apps
# Migrate from old directory structure to new versioned structure
migrate_directory_structure() {
  local old_location="$1"
  local old_version
  old_version=$(cat "$old_location/PG_VERSION")

  local new_location="$BASE_DIR/$old_version/docker"

  dm_log "Detected data in old location: [$old_location]"
  dm_log "Migrating to new structure: [$new_location]"

  if [ -d "$new_location" ] && [ "$(ls -A "$new_location")" ]; then
    dm_log "ERROR: Target location [$new_location] already exists and is not empty."
    return 1
  fi

  # Create parent directory
  if ! mkdir -p "$new_location"; then
    dm_log "ERROR: Failed to create parent directory [$new_location]"
    return 1
  fi

  # Ensure both locations are on the same filesystem
  check_same_filesystem "$old_location" "$new_location" || return 1

  # Use rsync to copy everything, preserving permissions
  local data_size
  data_size=$(get_data_size "$old_location")
  dm_log "Moving data from [$old_location] to [$new_location] with rsync (${data_size})"
  dm_log "This may take a while depending on database size..."
  # Use rsync to copy everything (including empty directories), except the newly created version directory
  # --archive preserves permissions, --remove-source-files deletes files after copy
  rsync --archive --remove-source-files --exclude="/$old_version" "$old_location/" "$new_location/" || return 1

  dm_log "Cleaning up empty directories from [$old_location]"
  # Recursively delete empty directories, but exclude all versioned directories (numeric names)
  # This handles cases like base/, pg_wal/, etc. that are now empty after rsync
  find "$old_location" -mindepth 1 -type d -empty \
    ! -path "$old_location/[0-9]*" \
    ! -path "$old_location/[0-9]*/*" \
    -delete 2>/dev/null || true

  dm_log "Migration complete. Data now at: [$new_location]"
  return 0
}

# Perform the upgrade
perform_upgrade() {
  local old_data_dir="$1"
  local old_version="$2"
  local new_version="$3"

  up_log "Starting upgrade from PostgreSQL [$old_version] to [$new_version]"

  local old_bin_path
  old_bin_path=$(get_bin_path "$old_version")
  local new_bin_path
  new_bin_path=$(get_bin_path "$new_version")

  empty_line

  # Verify binaries exist
  if [ ! -f "$old_bin_path/pg_upgrade" ]; then
    up_log "ERROR: Old PostgreSQL [$old_version] binaries not found at [$old_bin_path]"
    return 1
  fi

  if [ ! -f "$new_bin_path/pg_upgrade" ]; then
    up_log "ERROR: New PostgreSQL [$new_version] binaries not found at [$new_bin_path]"
    return 1
  fi

  empty_line

  local new_data_dir="$BASE_DIR/$new_version/docker"

  if [ -d "$new_data_dir" ]; then
    up_log "ERROR: Directory [$new_data_dir] already exists."
    return 1
  fi

  # Initialize new data directory
  up_log "Initializing new data directory: $new_data_dir"
  if ! mkdir -p "$new_data_dir" ; then
    up_log "ERROR: Failed to create new data directory [$new_data_dir]"
    return 1
  fi

  export PGUSER="$POSTGRES_USER"
  export PGDATA="$new_data_dir"

  # Check if old cluster has checksums enabled
  local old_checksums_enabled=false
  if "$old_bin_path"/pg_checksums --check --pgdata="$old_data_dir" >/dev/null 2>&1; then
    old_checksums_enabled=true
    up_log "Old cluster has checksums enabled"
  else
    up_log "Old cluster has checksums disabled"
  fi

  # Add checksum flag to POSTGRES_INITDB_ARGS
  local original_initdb_args="${POSTGRES_INITDB_ARGS:-}"
  if [ "$old_checksums_enabled" = true ]; then
    export POSTGRES_INITDB_ARGS="${original_initdb_args} --data-checksums"
  else
    export POSTGRES_INITDB_ARGS="${original_initdb_args} --no-data-checksums"
  fi

  up_log "Using docker_init_database_dir from upstream entrypoint"
  empty_line
  docker_init_database_dir
  empty_line

  # Restore original POSTGRES_INITDB_ARGS
  export POSTGRES_INITDB_ARGS="$original_initdb_args"

  # Create backup before upgrade
  local timestamp
  timestamp=$(date +%Y%m%d%H%M%S)
  local backup_dir="$BASE_DIR/backups"
  if ! mkdir -p "$backup_dir"; then
    up_log "ERROR: Failed to create backup directory [$backup_dir]"
    return 1
  fi

  local backup_file="$backup_dir/pre-upgrade-${old_version}-to-${new_version}-${timestamp}.tar.zst"
  local backup_data_size
  backup_data_size=$(get_data_size "$old_data_dir")
  up_log "Creating backup: $backup_file (${backup_data_size})"
  up_log "This may take a while depending on database size..."
  tar --zstd -cf "$backup_file" -C "$(dirname "$old_data_dir")" "$(basename "$old_data_dir")"

  # Try to set restrictive permissions on backup to protect sensitive data
  if chmod 600 "$backup_file"; then
    up_log "Backup secured with 600 permissions"
  else
    up_log "WARNING: Failed to set permissions on backup file [$backup_file]"
  fi

  # Compatibility check
  up_log "Running compatibility check..."
  if ! "$new_bin_path"/pg_upgrade \
    --old-bindir="$old_bin_path" \
    --new-bindir="$new_bin_path" \
    --old-datadir="$old_data_dir" \
    --new-datadir="$new_data_dir" \
    --socketdir=/var/run/postgresql \
    --link \
    --check; then
    up_log "ERROR: Compatibility check failed"
    up_log "Cleaning up new data directory [$new_data_dir]"
    if ! rm -rf "$new_data_dir"; then
      up_log "WARNING: Failed to remove new data directory [$new_data_dir] after failed compatibility check"
    fi
    return 1
  fi

  up_log "Compatibility check passed"

  # Create and change to a dedicated directory for pg_upgrade output files
  local upgrade_work_dir="$BASE_DIR/pg_upgrade_work"
  if ! mkdir -p "$upgrade_work_dir"; then
    up_log "ERROR: Failed to create pg_upgrade work directory [$upgrade_work_dir]"
    return 1
  fi
  if ! cd "$upgrade_work_dir"; then
    up_log "ERROR: Failed to change to pg_upgrade work directory [$upgrade_work_dir]"
    return 1
  fi

  # Perform actual upgrade
  up_log "Performing upgrade..."
  up_log "SQL scripts will be created in: $upgrade_work_dir"
  if ! "$new_bin_path"/pg_upgrade \
    --old-bindir="$old_bin_path" \
    --new-bindir="$new_bin_path" \
    --old-datadir="$old_data_dir" \
    --new-datadir="$new_data_dir" \
    --socketdir=/var/run/postgresql \
    --link; then
    up_log "ERROR: Upgrade failed"
    up_log "Cleaning up new data directory: $new_data_dir"
    rm -rf "$new_data_dir"
    return 1
  fi

  up_log "Upgrade completed successfully"

  # Find SQL files generated by pg_upgrade in the work directory
  local sql_files
  sql_files=$(find . -maxdepth 1 -name "*.sql" -type f 2>/dev/null || true)

  # Run post-upgrade SQL scripts if any were generated
  if ! run_post_upgrade_tasks "$new_data_dir" "$sql_files"; then
    up_log "ERROR: Post-upgrade tasks failed"
    return 1
  fi

  # Copy pg_hba.conf (authentication rules - safe to copy between versions)
  if [ -f "$old_data_dir/pg_hba.conf" ]; then
    cp "$old_data_dir/pg_hba.conf" "$new_data_dir/pg_hba.conf"
    up_log "Copied [$old_data_dir/pg_hba.conf] to [$new_data_dir/pg_hba.conf]"
  fi

  # Note: postgresql.conf is NOT copied automatically as it may contain
  # version-specific settings. Review and merge manually if needed.
  if [ -f "$old_data_dir/postgresql.conf" ]; then
    up_log "NOTE: Old postgresql.conf available at $old_data_dir/postgresql.conf"
    up_log "      Review and merge settings manually if needed. (Only if you made custom changes)"
  fi

  up_log "Upgrade process complete"
  up_log "Old data preserved at: $old_data_dir"
  up_log "New data location: $new_data_dir"
  up_log "Backup available at: $backup_file"
  return 0
}

log "Starting entrypoint with migration and upgrade handling"

if [ -z "$TARGET_VERSION" ]; then
  log "ERROR: TARGET_VERSION is not set"
  exit 1
fi

correct_pg_data="$BASE_DIR/$TARGET_VERSION/docker"
if [ "$PGDATA" != "$correct_pg_data" ]; then
  log "ERROR: PGDATA is not set to the correct location [$PGDATA != $correct_pg_data]"
  exit 1
fi

check_writable "$BASE_DIR" || exit 1
check_writable "/var/run/postgresql" || exit 1
check_dir_owner_match "$BASE_DIR" || exit 1

target_version_dir="$BASE_DIR/$TARGET_VERSION/docker"
if [ -d "$target_version_dir" ] && [ "$(ls -A "$target_version_dir" 2>/dev/null)" ]; then
  # Directory exists and is not empty - check if it's a valid completed upgrade
  if [ ! -f "$target_version_dir/PG_VERSION" ]; then
    log "ERROR: Target version directory [$target_version_dir] already exists and is not empty, but PG_VERSION file not found."
    log "This may indicate a partial/failed upgrade. Please investigate and remove/rename the existing directory."
    exit 1
  fi

  existing_version=$(cat "$target_version_dir/PG_VERSION")
  if [ "$existing_version" != "$TARGET_VERSION" ]; then
    log "ERROR: Target version directory [$target_version_dir] exists with wrong version [$existing_version], expected [$TARGET_VERSION]."
    log "Cannot proceed with upgrade. Please investigate and remove/rename the existing directory."
    exit 1
  fi

  log "Target version directory already exists with correct version [$TARGET_VERSION]. Upgrade already completed."
  log "Exiting successfully."
  exit 0
fi

# TODO: Remove once postgres 17 is removed from Apps
# Check if we need to do directory migration first
if old_location=$(detect_old_data_location); then
  log "Old directory structure detected, performing migration"
  if ! migrate_directory_structure "$old_location"; then
    log "ERROR: Migration failed"
    exit 1
  fi
else
  log "No migration needed from old data location."
fi

# Now check for version-specific directories and find the HIGHEST version
found_version=""
found_data_dir=""
highest_version=0
checked_count=0
for version_dir in "$BASE_DIR"/*/docker; do
  # Skip if glob didn't match any directories
  [ -e "$version_dir" ] || continue

  checked_count=$((checked_count + 1))
  log "Checking directory: $version_dir"

  if [ -f "$version_dir/PG_VERSION" ]; then
    this_version=$(cat "$version_dir/PG_VERSION")
    log "  - Found database: PostgreSQL $this_version"

    # Track the highest version found
    if [ "$this_version" -gt "$highest_version" ]; then
      highest_version="$this_version"
      found_version="$this_version"
      found_data_dir="$version_dir"
    fi
  else
    log "  - No PG_VERSION file found"
  fi
done

# Check if we found any database
if [ -z "$found_version" ]; then
  if [ "$checked_count" -eq 0 ]; then
    log "No version directories found in $BASE_DIR/*/docker pattern."
  else
    log "Checked $checked_count directories but found no valid PostgreSQL databases."
  fi
  log "Assuming this is a fresh install."
  exit 0
fi

log "Using highest version found: PostgreSQL [$found_version] at [$found_data_dir]"

# Use the found data directory
DATA_DIR="$found_data_dir"

# TODO: Remove once postgres 17 is removed from Apps
# Migrate timezones before checking versions
if ! migrate_timezones "$DATA_DIR"; then
  log "ERROR: Timezone migration failed"
  exit 1
fi

OLD_VERSION=$(cat "$DATA_DIR/PG_VERSION")
log "Current version: $OLD_VERSION"
log "Target version: $TARGET_VERSION"

# Don't do anything if we're already at the target version.
if [ "$OLD_VERSION" -eq "$TARGET_VERSION" ]; then
  log "Already at target version $TARGET_VERSION"
  exit 0
fi

# Fail if we're downgrading.
if [ "$OLD_VERSION" -gt "$TARGET_VERSION" ]; then
  log "Cannot downgrade from $OLD_VERSION to $TARGET_VERSION"
  exit 1
fi

if ! perform_upgrade "$DATA_DIR" "$OLD_VERSION" "$TARGET_VERSION"; then
  log "ERROR: Upgrade failed"
  exit 1
fi

log "Upgrade complete. New database available at: $BASE_DIR/$TARGET_VERSION/docker"
log "Done."
